# Task-3
## Vision Transformer
Vision Transformers (ViTs) challenge the dominance of Convolutional Neural Networks (CNNs) in computer vision. Unlike CNNs that rely on local filters, ViTs break images into patches and process them through a Transformer architecture. This allows ViTs to capture long-range dependencies between different parts of the image, leading to a better understanding of complex relationships. Additionally, ViTs are less sensitive to data augmentation techniques, potentially working well with smaller datasets. This focus on global features makes ViTs well-suited for tasks like object detection, scene understanding, and image classification.

Implementation for the vision transformer can be found in `VisionTransformer.py`